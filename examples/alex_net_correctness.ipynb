{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Switch to double, for testing correctness\n",
    "os.environ['UNIT_TESTING'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] tc_composer.settings - Setting default tensor type: torch.cuda.DoubleTensor\n",
      "[INFO] tc_composer.settings - Setting epsilon: 1e-16\n",
      "[INFO] tc_composer.settings - Input tensor shape checking: True\n",
      "[INFO] tc_composer.settings - Saving compiled options in: /home/ubuntu/tc_composer/options\n",
      "[INFO] tc_composer.settings - Current CUDA device: Tesla V100-SXM2-16GB\n",
      "[INFO] tc_composer.settings - Listing CUDA devices:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 CUDA devices\n",
      "id 0    b'Tesla V100-SXM2-16GB'                              [SUPPORTED]\n",
      "                      compute capability: 7.0\n",
      "                           pci device id: 30\n",
      "                              pci bus id: 0\n",
      "Summary:\n",
      "\t1/1 devices are supported\n"
     ]
    }
   ],
   "source": [
    "import tensor_comprehensions as tc\n",
    "import torch\n",
    "import tc_composer\n",
    "from torch.nn import Conv2d\n",
    "from tc_composer.implementation import AlexNet\n",
    "from tc_composer.func.affine_transform import FusedAffineTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet\n",
    "Implementing https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_net = AlexNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "in_channels, in_height, in_width = 3, 227, 227\n",
    "tc_inp = tc_image = torch.randn(batch_size, in_channels, in_height, in_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def AlexNet(\n",
      "    double(1, 3, 227, 227) input,\n",
      "    double(64, 3, 11, 11) weight,\n",
      "    double(64) bias,\n",
      "    double(192, 64, 5, 5) weight1,\n",
      "    double(192) bias1,\n",
      "    double(384, 192, 3, 3) weight2,\n",
      "    double(384) bias2,\n",
      "    double(256, 384, 3, 3) weight3,\n",
      "    double(256) bias3,\n",
      "    double(256, 256, 3, 3) weight4,\n",
      "    double(256) bias4,\n",
      "    double(4096, 9216) weight5,\n",
      "    double(4096) bias5,\n",
      "    double(4096, 4096) weight6,\n",
      "    double(4096) bias6,\n",
      "    double(1000, 4096) weight7,\n",
      "    double(1000) bias7\n",
      ") -> (\n",
      "    double(1, 64, 56, 56) output,\n",
      "    double(1, 64, 27, 27) output1,\n",
      "    double(1, 192, 27, 27) output2,\n",
      "    double(1, 192, 13, 13) output3,\n",
      "    double(1, 384, 13, 13) output4,\n",
      "    double(1, 256, 13, 13) output5,\n",
      "    double(1, 256, 13, 13) output6,\n",
      "    double(1, 256, 6, 6) output7,\n",
      "    double(1, 4096) output8,\n",
      "    double(1, 4096) output9,\n",
      "    double(1, 1000) output10\n",
      ")\n",
      "{\n",
      "    output(n, m, h, w) +=! input(n, c, max(min(4*h + kh - 2, 226), 0), max(min(4*w + kw - 2, 226), 0)) * weight(m, c, kh, kw) \n",
      "                                  * fmin(1.0, fmax(0.0, (1 + 4*h + kh - 2) * (227 - (4*h + kh - 2))))\n",
      "                                  * fmin(1.0, fmax(0.0, (1 + 4*w + kw - 2) * (227 - (4*w + kw - 2))))\n",
      "        where kh in 0:11, kw in 0:11, h in 0:56, w in 0:56\n",
      "    \n",
      "    output1(b, c, h, w) max=! fmax(output(b, c, h*2 + kh, w*2 + kw) + bias(c), 0)\n",
      "        where kh in 0:3, kw in 0:3\n",
      "    \n",
      "    output2(n, m, h, w) +=! output1(n, c, max(min(h + kh - 2, 26), 0), max(min(w + kw - 2, 26), 0)) * weight1(m, c, kh, kw) \n",
      "                                  * fmin(1.0, fmax(0.0, (1 + h + kh - 2) * (27 - (h + kh - 2))))\n",
      "                                  * fmin(1.0, fmax(0.0, (1 + w + kw - 2) * (27 - (w + kw - 2))))\n",
      "        where kh in 0:5, kw in 0:5, h in 0:27, w in 0:27\n",
      "    \n",
      "    output3(b, c, h, w) max=! fmax(output2(b, c, h*2 + kh, w*2 + kw) + bias1(c), 0)\n",
      "        where kh in 0:3, kw in 0:3\n",
      "    \n",
      "    output4(n, m, h, w) +=! output3(n, c, max(min(h + kh - 1, 12), 0), max(min(w + kw - 1, 12), 0)) * weight2(m, c, kh, kw) \n",
      "                                  * fmin(1.0, fmax(0.0, (1 + h + kh - 1) * (13 - (h + kh - 1))))\n",
      "                                  * fmin(1.0, fmax(0.0, (1 + w + kw - 1) * (13 - (w + kw - 1))))\n",
      "        where kh in 0:3, kw in 0:3, h in 0:13, w in 0:13\n",
      "    \n",
      "    output5(n, m, h, w) +=! fmax(output4(n, c, max(min(h + kh - 1, 12), 0), max(min(w + kw - 1, 12), 0)) + bias2(c), 0) * weight3(m, c, kh, kw) \n",
      "                                  * fmin(1.0, fmax(0.0, (1 + h + kh - 1) * (13 - (h + kh - 1))))\n",
      "                                  * fmin(1.0, fmax(0.0, (1 + w + kw - 1) * (13 - (w + kw - 1))))\n",
      "        where kh in 0:3, kw in 0:3, h in 0:13, w in 0:13\n",
      "    \n",
      "    output6(n, m, h, w) +=! fmax(output5(n, c, max(min(h + kh - 1, 12), 0), max(min(w + kw - 1, 12), 0)) + bias3(c), 0) * weight4(m, c, kh, kw) \n",
      "                                  * fmin(1.0, fmax(0.0, (1 + h + kh - 1) * (13 - (h + kh - 1))))\n",
      "                                  * fmin(1.0, fmax(0.0, (1 + w + kw - 1) * (13 - (w + kw - 1))))\n",
      "        where kh in 0:3, kw in 0:3, h in 0:13, w in 0:13\n",
      "    \n",
      "    output7(b, c, h, w) max=! fmax(output6(b, c, h*2 + kh, w*2 + kw) + bias4(c), 0)\n",
      "        where kh in 0:3, kw in 0:3\n",
      "    \n",
      "    output8(b, n) +=! output7(b, i/36, (i%36)/6, i%6) * weight5(n, i)\n",
      "        where i in 0:9216, n in 0:4096\n",
      "    \n",
      "    output9(b, n) +=! fmax(output8(b, i) + bias5(i), 0) * weight6(n, i)\n",
      "    \n",
      "    output10(b, n) +=! fmax(output9(b, i) + bias6(i), 0) * weight7(n, i)\n",
      "    \n",
      "    output10(b, n) = output10(b, n) + bias7(n)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(alex_net.tc_def(tc_inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import AlexNet\n",
    "\n",
    "torch_alex_net = AlexNet()\n",
    "torch_alex_net.train(False)  # Disable dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 11, 11])\n",
      "torch.Size([64, 3, 11, 11])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([192, 64, 5, 5])\n",
      "torch.Size([192, 64, 5, 5])\n",
      "torch.Size([192])\n",
      "torch.Size([192])\n",
      "torch.Size([384, 192, 3, 3])\n",
      "torch.Size([384, 192, 3, 3])\n",
      "torch.Size([384])\n",
      "torch.Size([384])\n",
      "torch.Size([256, 384, 3, 3])\n",
      "torch.Size([256, 384, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([4096, 9216])\n",
      "torch.Size([4096, 9216])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096, 4096])\n",
      "torch.Size([4096, 4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([4096])\n",
      "torch.Size([1000, 4096])\n",
      "torch.Size([1000, 4096])\n",
      "torch.Size([1000])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "for p, p1 in zip(torch_alex_net.parameters(), alex_net.params):\n",
    "    p.data = p1.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "start_option = tc.MappingOptions('naive')\\\n",
    "    .mapToBlocks([1000, 6, 512])\\\n",
    "    .mapToThreads([6, 6])\\\n",
    "    .tile([16384, 48, 1024, 1, 4096])\\\n",
    "    .intraTileScheduleFusionStrategy('Max')\\\n",
    "    .outerScheduleFusionStrategy('Max')\\\n",
    "    .unroll(32)\\\n",
    "    .fixParametersBeforeScheduling(False)\\\n",
    "    .matchLibraryCalls(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] AlexNet - Compiling for input shape - [(1, 3, 227, 227)].\n"
     ]
    }
   ],
   "source": [
    "alex_net.recompile(tc_inp, option=start_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = alex_net(tc_inp).data\n",
    "two = torch_alex_net.forward(tc_inp).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.testing.assert_allclose(one, two, rtol=1e-10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
