{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] tc_composer.settings - Setting default tensor type: torch.cuda.FloatTensor\n",
      "[INFO] tc_composer.settings - Setting epsilon: 1e-16\n",
      "[INFO] tc_composer.settings - Input tensor shape checking: False\n",
      "[INFO] tc_composer.settings - Saving compiled options in: /home/ubuntu/tc_composer/options\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from tc_composer.func.function_with_params import FunctionWithParams\n",
    "from tc_composer.unique_name import TensorName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP3(FunctionWithParams):\n",
    "    def __init__(self, in_n: int, hidden0: int, hidden1: int, out_n: int):\n",
    "        in_name = TensorName(dim=2, sizes='B N'.split(), prefix='input')\n",
    "        output0 = TensorName(dim=2, sizes='B H'.split(), prefix='output')\n",
    "        output1 = TensorName(dim=2, sizes='B H'.split(), prefix='output')\n",
    "        output2 = TensorName(dim=2, sizes='B O'.split(), prefix='output')\n",
    "        in_name.sizes[1] = in_n\n",
    "        super(MLP3, self).__init__(\n",
    "            # The order in which names are listed does not matter, as long as \n",
    "            # they are retrieved correctly in self.def_body \n",
    "            in_names=[in_name], \n",
    "            outs_to_keep=[output2],\n",
    "            outs_to_discard=(output0, output1)\n",
    "        )\n",
    "        self.in_n = in_n\n",
    "        self.hidden0 = hidden0\n",
    "        self.hidden1 = hidden1\n",
    "        self.out_n = out_n\n",
    "        \n",
    "    @property\n",
    "    def named_params(self):\n",
    "        # The order in which names are listed does not matter, as long as \n",
    "            # they are retrieved correctly in self.def_body\n",
    "        return TensorName.make_pair(sizes=(self.hidden0, in_n), prefix='weight'), \\\n",
    "               TensorName.make_pair(sizes=(self.hidden0,), prefix='bias'), \\\n",
    "               TensorName.make_pair(sizes=(self.hidden1, self.hidden0), prefix='weight'), \\\n",
    "               TensorName.make_pair(sizes=(self.hidden1,), prefix='bias'), \\\n",
    "               TensorName.make_pair(sizes=(self.out_n, self.hidden1), prefix='weight'), \\\n",
    "               TensorName.make_pair(sizes=(self.out_n,), prefix='bias'), \\\n",
    "\n",
    "    @property\n",
    "    def def_body(self):\n",
    "        input, = self.in_names\n",
    "        output0, output1, output2 = *self.outs_to_discard, *self.outs_to_keep\n",
    "        (weight0, bias0,\n",
    "         weight1, bias1,\n",
    "         weight2, bias2) = tuple(n for n, _ in self.named_params)\n",
    "        \n",
    "        return (\n",
    "            f\"{output0}(b, n) +=! {input}(b, i) * {weight0}(n, i)\\n\"\n",
    "            # Combining point-wise operations with the next linear transformation\n",
    "            f\"{output1}(b, n) +=! fmax({output0}(b, i) + {bias0}(i), 0) * {weight1}(n, i)\\n\"\n",
    "            f\"{output2}(b, n) +=! fmax({output1}(b, i) + {bias1}(i), 0) * {weight2}(n, i)\\n\"\n",
    "            f\"{output2}(b, n) = fmax({output2}(b, n) + {bias2}(n), 0)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "in_n = 128\n",
    "hidden_dim = 64\n",
    "\n",
    "image = torch.rand(batch_size, in_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def MLP3(\n",
      "    float(B,128) input,\n",
      "    float(64,128) weight,\n",
      "    float(64) bias,\n",
      "    float(64,64) weight1,\n",
      "    float(64) bias1,\n",
      "    float(64,64) weight2,\n",
      "    float(64) bias2\n",
      ") -> (output, output1, output2)\n",
      "{\n",
      "    output(b, n) +=! input(b, i) * weight(n, i)\n",
      "    output1(b, n) +=! fmax(output(b, i) + bias(i), 0) * weight1(n, i)\n",
      "    output2(b, n) +=! fmax(output1(b, i) + bias1(i), 0) * weight2(n, i)\n",
      "    output2(b, n) = fmax(output2(b, n) + bias2(n), 0)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tc_mlp3 = MLP3(in_n=in_n, hidden0=hidden_dim, hidden1=hidden_dim, out_n=hidden_dim)\n",
    "print(tc_mlp3.tc_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autotune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] MLP3 - Loading start options from file - /home/ubuntu/tc_composer/options/MLP3_Tesla_K80\n",
      "[WARNING] MLP3 - No option loaded from file for input shape - [(32, 128)].\n",
      "[WARNING] MLP3 - Initializing naive options.\n"
     ]
    }
   ],
   "source": [
    "# Takes a long time\n",
    "option = tc_mlp3.tune_options([image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] MLP3 - Compiling for input shape - [(32, 128)].\n"
     ]
    }
   ],
   "source": [
    "tc_mlp3.recompile(image, option=option)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, matmul, relu_ as relu_inplace\n",
    "\n",
    "\n",
    "def torch_mlp3(inp, params):\n",
    "    (weight0, bias0, \n",
    "    weight1, bias1, \n",
    "    weight2, bias2) = params\n",
    "    \n",
    "    out0 = relu_inplace(matmul(inp, weight0).add_(bias0))\n",
    "    out1 = relu_inplace(matmul(out0, weight1).add_(bias1))\n",
    "    out2 = relu_inplace(matmul(out1, weight2).add_(bias2))\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "for t in tc_mlp3.params:\n",
    "    if t.dim() > 1:\n",
    "        t = t.transpose(0, 1).contiguous()\n",
    "    params.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.testing.assert_allclose(\n",
    "    tc_mlp3(image)[-1].cpu().detach().numpy(),\n",
    "    torch_mlp3(image, params).cpu().detach().numpy(),\n",
    "    rtol=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mytime(iters, prepend, runFun, *args):\n",
    "    timesCPU = []\n",
    "    timesCPUAndGPU = []\n",
    "    for i in range(iters):\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.clock()\n",
    "        outputs = runFun(*args)\n",
    "        timesCPU.append(time.clock() - start)\n",
    "        torch.cuda.synchronize()\n",
    "        timesCPUAndGPU.append(time.clock() - start)\n",
    "    print(\"#################################################################\")\n",
    "    timesCPU = sorted(timesCPU)\n",
    "    print(\n",
    "        \"{} Total CPU time to launch kernel: min {}us, p50 {}us, p90 {}us, max {}us\".\n",
    "        format(\n",
    "            prepend,\n",
    "            int(timesCPU[0] * 1e6),\n",
    "            int(timesCPU[int(len(timesCPU) // 2)] * 1e6),\n",
    "            int(timesCPU[int((len(timesCPU) * 9) // 10)] * 1e6),\n",
    "            int(timesCPU[len(timesCPU) - 1] * 1e6),\n",
    "        ))\n",
    "    timesCPUAndGPU = sorted(timesCPUAndGPU)\n",
    "    print(\n",
    "        \"{} Total CPU launch + GPU kernel time: min {}us, p50 {}us, p90 {}us, max {}us\".\n",
    "        format(\n",
    "            prepend,\n",
    "            int(timesCPUAndGPU[0] * 1e6),\n",
    "            int(timesCPUAndGPU[int(len(timesCPUAndGPU) // 2)] * 1e6),\n",
    "            int(timesCPUAndGPU[int((len(timesCPUAndGPU) * 9) // 10)] * 1e6),\n",
    "            int(timesCPUAndGPU[len(timesCPUAndGPU) - 1] * 1e6),\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "raw tuned options\t Total CPU time to launch kernel: min 117us, p50 119us, p90 121us, max 679us\n",
      "raw tuned options\t Total CPU launch + GPU kernel time: min 149us, p50 153us, p90 154us, max 694us\n"
     ]
    }
   ],
   "source": [
    "mytime(\n",
    "    10000,\n",
    "    \"raw tuned options\\t\",\n",
    "    lambda: tc_mlp3(image)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "Pytorch\t Total CPU time to launch kernel: min 90us, p50 94us, p90 99us, max 1800us\n",
      "Pytorch\t Total CPU launch + GPU kernel time: min 103us, p50 120us, p90 152us, max 1817us\n"
     ]
    }
   ],
   "source": [
    "mytime(\n",
    "    10000,\n",
    "    \"Pytorch\\t\",\n",
    "    lambda: torch_mlp3(image, params)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
