{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import tensor_comprehensions as tc\n",
    "from torch import nn\n",
    "from tc_composer.func.function_with_params import FunctionWithParams\n",
    "from tc_composer.settings import TYPE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP3(FunctionWithParams):\n",
    "    def __init__(self, in_n: int, hidden0: int, hidden1: int, out_n: int, out_buffers = ()):\n",
    "        super(MLP3, self).__init__(out_buffers=out_buffers)\n",
    "        weight0 = torch.rand(hidden0, in_n)\n",
    "        weight1 = torch.rand(hidden1, hidden0)\n",
    "        weight2 = torch.rand(out_n, hidden1)\n",
    "        bias0 = torch.rand(hidden0)\n",
    "        bias1 = torch.rand(hidden1)\n",
    "        bias2 = torch.rand(out_n)\n",
    "        \n",
    "        self._params = (weight0, bias0, \n",
    "                        weight1, bias1, \n",
    "                        weight2, bias2)\n",
    "    \n",
    "    @property\n",
    "    def params(self):\n",
    "        # A list of params in the same order in which \n",
    "        # they are listed in the TC definition\n",
    "        return self._params\n",
    "\n",
    "    @property\n",
    "    def tc_def(self):\n",
    "        return (\n",
    "            # Inputs to the function should be listed before weights and biases of the layer, and other params\n",
    "            # Params should be listed in the same order as `self.params`\n",
    "            f\"def MLP3({TYPE_NAME}(batch_size, in_n) input,\\n\"\n",
    "            f\"  {TYPE_NAME}(hidden0, in_n) weight0,\\n\"\n",
    "            f\"  {TYPE_NAME}(hidden0) bias0,\\n\"\n",
    "            f\"  {TYPE_NAME}(hidden1, hidden0) weight1,\\n\"\n",
    "            f\"  {TYPE_NAME}(hidden1) bias1,\\n\"\n",
    "            f\"  {TYPE_NAME}(out_n, hidden1) weight2,\\n\"\n",
    "            f\"  {TYPE_NAME}(out_n) bias2\\n\"\n",
    "            \") -> (output0, output1, output2)\\n\"\n",
    "            \"{\\n\"\n",
    "            \"   output0(b, n) +=! input(b, i) * weight0(n, i)\\n\"\n",
    "            # Combining point-wise operations with the next linear transformation\n",
    "            \"   output1(b, n) +=! fmax(output0(b, i) + bias0(i), 0) * weight1(n, i)\\n\"\n",
    "            \"   output2(b, n) +=! fmax(output1(b, i) + bias1(i), 0) * weight2(n, i)\\n\"\n",
    "            \"   output2(b, n) = fmax(output2(b, n) + bias2(n), 0)\\n\"\n",
    "            \"}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "in_n = 128\n",
    "hidden_dim = 64\n",
    "\n",
    "image = torch.rand(batch_size, in_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def MLP3(float(batch_size, in_n) input,\n",
      "  float(hidden0, in_n) weight0,\n",
      "  float(hidden0) bias0,\n",
      "  float(hidden1, hidden0) weight1,\n",
      "  float(hidden1) bias1,\n",
      "  float(out_n, hidden1) weight2,\n",
      "  float(out_n) bias2\n",
      ") -> (output0, output1, output2)\n",
      "{\n",
      "   output0(b, n) +=! input(b, i) * weight0(n, i)\n",
      "   output1(b, n) +=! fmax(output0(b, i) + bias0(i), 0) * weight1(n, i)\n",
      "   output2(b, n) +=! fmax(output1(b, i) + bias1(i), 0) * weight2(n, i)\n",
      "   output2(b, n) = fmax(output2(b, n) + bias2(n), 0)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tc_mlp3 = MLP3(in_n=in_n, hidden0=hidden_dim, hidden1=hidden_dim, out_n=hidden_dim)\n",
    "print(tc_mlp3.tc_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autotune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] MLP3 - Appending results to /home/ubuntu/tc_composer/options/MLP3_Tesla_K80\n"
     ]
    }
   ],
   "source": [
    "option = tc_mlp3.tune_options([image], tuner_config=tc.TunerConfig().number_elites(20).generations(40), start_options=option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] MLP3 - Compiling for input shape - [(32, 128)].\n"
     ]
    }
   ],
   "source": [
    "tc_mlp3.recompile(image, option=option)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, matmul, relu_ as relu_inplace\n",
    "\n",
    "\n",
    "def torch_mlp3(inp, params):\n",
    "    (weight0, bias0, \n",
    "    weight1, bias1, \n",
    "    weight2, bias2) = params\n",
    "    \n",
    "    out0 = relu_inplace(matmul(inp, weight0).add_(bias0))\n",
    "    out1 = relu_inplace(matmul(out0, weight1).add_(bias1))\n",
    "    out2 = relu_inplace(matmul(out1, weight2).add_(bias2))\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "for t in tc_mlp3.params:\n",
    "    if t.dim() > 1:\n",
    "        t = t.transpose(0, 1).contiguous()\n",
    "    params.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.testing.assert_allclose(\n",
    "    tc_mlp3(image)[-1].cpu().detach().numpy(),\n",
    "    torch_mlp3(image, params).cpu().detach().numpy(),\n",
    "    rtol=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mytime(iters, prepend, runFun, *args):\n",
    "    timesCPU = []\n",
    "    timesCPUAndGPU = []\n",
    "    for i in range(iters):\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.clock()\n",
    "        outputs = runFun(*args)\n",
    "        timesCPU.append(time.clock() - start)\n",
    "        torch.cuda.synchronize()\n",
    "        timesCPUAndGPU.append(time.clock() - start)\n",
    "    print(\"#################################################################\")\n",
    "    timesCPU = sorted(timesCPU)\n",
    "    print(\n",
    "        \"{} Total CPU time to launch kernel: min {}us, p50 {}us, p90 {}us, max {}us\".\n",
    "        format(\n",
    "            prepend,\n",
    "            int(timesCPU[0] * 1e6),\n",
    "            int(timesCPU[int(len(timesCPU) // 2)] * 1e6),\n",
    "            int(timesCPU[int((len(timesCPU) * 9) // 10)] * 1e6),\n",
    "            int(timesCPU[len(timesCPU) - 1] * 1e6),\n",
    "        ))\n",
    "    timesCPUAndGPU = sorted(timesCPUAndGPU)\n",
    "    print(\n",
    "        \"{} Total CPU launch + GPU kernel time: min {}us, p50 {}us, p90 {}us, max {}us\".\n",
    "        format(\n",
    "            prepend,\n",
    "            int(timesCPUAndGPU[0] * 1e6),\n",
    "            int(timesCPUAndGPU[int(len(timesCPUAndGPU) // 2)] * 1e6),\n",
    "            int(timesCPUAndGPU[int((len(timesCPUAndGPU) * 9) // 10)] * 1e6),\n",
    "            int(timesCPUAndGPU[len(timesCPUAndGPU) - 1] * 1e6),\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "raw tuned options\t Total CPU time to launch kernel: min 88us, p50 90us, p90 92us, max 667us\n",
      "raw tuned options\t Total CPU launch + GPU kernel time: min 130us, p50 133us, p90 135us, max 716us\n"
     ]
    }
   ],
   "source": [
    "inp = (image, *tc_mlp3.params)\n",
    "cache = tc_mlp3._FunctionWithParams__compilation_cache\n",
    "\n",
    "\n",
    "mytime(\n",
    "    10000,\n",
    "    \"raw tuned options\\t\",\n",
    "    lambda: cache.unchecked_run('MLP3', inp, out_buffers)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################################\n",
      "Pytorch\t Total CPU time to launch kernel: min 83us, p50 86us, p90 87us, max 1468us\n",
      "Pytorch\t Total CPU launch + GPU kernel time: min 99us, p50 115us, p90 151us, max 1488us\n"
     ]
    }
   ],
   "source": [
    "mytime(\n",
    "    10000,\n",
    "    \"Pytorch\\t\",\n",
    "    lambda: torch_mlp3(image, params)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
